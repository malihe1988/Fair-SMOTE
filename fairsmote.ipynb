{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNATY5oQp6UcMzzC+6RBI4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malihe1988/Fair-SMOTE/blob/master/fairsmote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "df = files.upload()"
      ],
      "metadata": {
        "id": "SApu4GWXbPkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk5YNmqzbGxd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,roc_curve,precision_recall_curve,PrecisionRecallDisplay,RocCurveDisplay,auc\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from IPython.display import FileLink"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "import pdb\n",
        "import unittest\n",
        "import random\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial import distance as dist\n",
        "from scipy.spatial import distance\n",
        "from sklearn.neighbors import NearestNeighbors as NN\n",
        "\n",
        "def get_ngbr(df, knn):\n",
        "            rand_sample_idx = random.randint(0, df.shape[0] - 1)\n",
        "            parent_candidate = df.iloc[rand_sample_idx]\n",
        "            ngbr = knn.kneighbors(parent_candidate.values.reshape(1,-1),3,return_distance=False)\n",
        "            candidate_1 = df.iloc[ngbr[0][0]]\n",
        "            candidate_2 = df.iloc[ngbr[0][1]]\n",
        "            candidate_3 = df.iloc[ngbr[0][2]]\n",
        "            return parent_candidate,candidate_2,candidate_3\n",
        "\n",
        "def generate_samples(no_of_samples,df,df_name):\n",
        "\n",
        "    total_data = df.values.tolist()\n",
        "    knn = NN(n_neighbors=5,algorithm='auto').fit(df)\n",
        "\n",
        "    for _ in range(no_of_samples):\n",
        "        cr = 0.8\n",
        "        f = 0.8\n",
        "        parent_candidate, child_candidate_1, child_candidate_2 = get_ngbr(df, knn)\n",
        "        new_candidate = []\n",
        "        for key,value in parent_candidate.items():\n",
        "            if isinstance(parent_candidate[key], bool):\n",
        "                new_candidate.append(parent_candidate[key] if cr < random.random() else not parent_candidate[key])\n",
        "            elif isinstance(parent_candidate[key], str):\n",
        "                new_candidate.append(random.choice([parent_candidate[key],child_candidate_1[key],child_candidate_2[key]]))\n",
        "            elif isinstance(parent_candidate[key], list):\n",
        "                temp_lst = []\n",
        "                for i, each in enumerate(parent_candidate[key]):\n",
        "                    temp_lst.append(parent_candidate[key][i] if cr < random.random() else\n",
        "                                    int(parent_candidate[key][i] +\n",
        "                                        f * (child_candidate_1[key][i] - child_candidate_2[key][i])))\n",
        "                new_candidate.append(temp_lst)\n",
        "            else:\n",
        "                new_candidate.append(abs(parent_candidate[key] + f * (child_candidate_1[key] - child_candidate_2[key])))\n",
        "        total_data.append(new_candidate)\n",
        "\n",
        "    final_df = pd.DataFrame(total_data)\n",
        "    if df_name == 'Adult':\n",
        "        final_df = final_df.rename(columns={0:\"age\",1:\"education-num\",2:\"race\",3:\"sex\",4:\"capital-gain\",5:\"capital-loss\",6:\"hours-per-week\",7:\"Probability\"}, errors=\"raise\")\n",
        "    if df_name == 'Compas':\n",
        "        final_df = final_df.rename(columns={0:\"sex\",1:\"age_cat\",2:\"race\",3:\"priors_count\",4:\"c_charge_degree\",5:\"Probability\"}, errors=\"raise\")\n",
        "    if df_name == 'Default':\n",
        "    \tfinal_df = final_df.rename(columns={0:\"ID\",1:\"LIMIT_BAL\",2:\"sex\",3:\"EDUCATION\",4:\"MARRIAGE\",5:\"AGE\",6:\"PAY_0\",7:\"PAY_2\",8:\"PAY_3\",9:\"PAY_4\",10:\"PAY_5\",11:\"PAY_6\",12:\"BILL_AMT1\",13:\"BILL_AMT2\",14:\"BILL_AMT3\",15:\"BILL_AMT4\",16:\"BILL_AMT5\",17:\"BILL_AMT6\",18:\"PAY_AMT1\",19:\"PAY_AMT2\",20:\"PAY_AMT3\",21:\"PAY_AMT4\",22:\"PAY_AMT5\",23:\"PAY_AMT6\",24:\"Probability\"}, errors=\"raise\")\n",
        "    if df_name == 'German':\n",
        "    \tfinal_df = final_df.rename(columns={0:\"sex\",1:\"age\",2:\"Probability\",3:\"credit_history=Delay\",4:\"credit_history=None/Paid\",5:\"credit_history=Other\",6:\"savings=500+\",7:\"savings=<500\",8:\"savings=Unknown/None\",9:\"employment=1-4 years\",10:\"employment=4+ years\",11:\"employment=Unemployed\"}, errors=\"raise\")\n",
        "    if df_name == 'Heart':\n",
        "    \tfinal_df = final_df.rename(columns={0:\"age\",1:\"sex\",2:\"cp\",3:\"trestbps\",4:\"chol\",5:\"fbs\",6:\"restecg\",7:\"thalach\",8:\"exang\",9:\"oldpeak\",10:\"slope\",11:\"ca\",12:\"thal\",13:\"Probability\"}, errors=\"raise\")\n",
        "    if df_name == 'Bank':\n",
        "        final_df = final_df.rename(columns={0:\"age\",1:\"default\",2:\"balance\",3:\"housing\",4:\"loan\",5:\"day\",6:\"duration\",7:\"campaign\",8:\"pdays\",9:\"previous\",10:\"Probability\"}, errors=\"raise\")\n",
        "    if df_name == 'Titanic':\n",
        "        final_df = final_df.rename(columns={0:\"Pclass\",1:\"sex\",2:\"Age\",3:\"SibSp\",4:\"Parch\",5:\"Fare\",6:\"Probability\"}, errors=\"raise\")\n",
        "    if df_name == 'Student':\n",
        "        final_df = final_df.rename(columns={0:'sex', 1:'age', 2:'Medu', 3:'Fedu', 4:'traveltime', 5:'studytime', 6:'failures',\n",
        "       7:'schoolsup', 8:'famsup', 9:'paid', 10:'activities', 11:'nursery', 12:'higher',\n",
        "       13:'internet', 14:'romantic', 15:'famrel', 16:'freetime', 17:'goout', 18:'Dalc', 19:'Walc',\n",
        "       20:'health', 21:'absences', 22:'G1', 23:'G2', 24:'Probability'}, errors=\"raise\")\n",
        "\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "2Ag8Z8KURfy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def compute_metrics(y_true, y_pred, sex, disp=True):\n",
        "    tp_u, tp_p, tn_u, tn_p, fp_u, fp_p, fn_p, fn_u, N_u, N_p = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
        "\n",
        "    for true_label, pred_label, sex_value in zip(y_true, y_pred, sex):\n",
        "        if sex_value == 0.0:\n",
        "            N_u += 1\n",
        "            if true_label == 1 and pred_label == 1:\n",
        "                tp_u += 1\n",
        "            elif true_label == 0 and pred_label == 0:\n",
        "                tn_u += 1\n",
        "            elif true_label == 0 and pred_label == 1:\n",
        "                fp_u += 1\n",
        "            elif true_label == 1 and pred_label == 0:\n",
        "                fn_u += 1\n",
        "        elif sex_value == 1.0:\n",
        "            N_p += 1\n",
        "            if true_label == 1 and pred_label == 1:\n",
        "                tp_p += 1\n",
        "            elif true_label == 0 and pred_label == 0:\n",
        "                tn_p += 1\n",
        "            elif true_label == 0 and pred_label == 1:\n",
        "                fp_p += 1\n",
        "            elif true_label == 1 and pred_label == 0:\n",
        "                fn_p += 1\n",
        "\n",
        "    # Calculate True Positive Rate (TPR), False Positive Rate (FPR), True Negative Rate (TNR), and False Negative Rate (FNR)\n",
        "    tpr_u = tp_u / (tp_u + fn_u) if (tp_u + fn_u) > 0 else 0.0\n",
        "    fpr_u = fp_u / (fp_u + tn_u) if (fp_u + tn_u) > 0 else 0.0\n",
        "    tnr_u = tn_u / (fp_u + tn_u) if (fp_u + tn_u) > 0 else 0.0\n",
        "    fnr_u = fn_u / (tp_u + fn_u) if (tp_u + fn_u) > 0 else 0.0\n",
        "\n",
        "    tpr_p = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0.0\n",
        "    fpr_p = fp_p / (fp_p + tn_p) if (fp_p + tn_p) > 0 else 0.0\n",
        "    tnr_p = tn_p / (fp_p + tn_p) if (fp_p + tn_p) > 0 else 0.0\n",
        "    fnr_p = fn_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0.0\n",
        "\n",
        "    # Calculate Precision, Recall, Specificity, and F1 Score\n",
        "    precision_u = tp_u / (tp_u + fp_u) if (tp_u + fp_u) > 0 else 0.0\n",
        "    recall_u = tp_u / (tp_u + fn_u) if (tp_u + fn_u) > 0 else 0.0\n",
        "    specificity_u = tn_u / (tn_u + fp_u) if (tn_u + fp_u) > 0 else 0.0\n",
        "    f1_score_u = 2 * tp_u / (2 * tp_u + fp_u + fn_u) if (2 * tp_u + fp_u + fn_u) > 0 else 0.0\n",
        "\n",
        "    precision_p = tp_p / (tp_p + fp_p) if (tp_p + fp_p) > 0 else 0.0\n",
        "    recall_p = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0.0\n",
        "    specificity_p = tn_p / (tn_p + fp_p) if (tn_p + fp_p) > 0 else 0.0\n",
        "    f1_score_p = 2 * tp_p / (2 * tp_p + fp_p + fn_p) if (2 * tp_p + fp_p + fn_p) > 0 else 0.0\n",
        "\n",
        "    # Calculate Disparate Impact\n",
        "    disparate_impact = ((tp_u + fp_u) / N_u) / ((tp_p + fp_p) / N_p) if ((tp_p + fp_p) / N_p) > 0 else 0.0\n",
        "\n",
        "    # Calculate Demo Parity\n",
        "    demo_parity = ((tp_u + fp_u) / N_u) - ((tp_p + fp_p) / N_p)\n",
        "\n",
        "    # Calculate Average Odds Difference\n",
        "    average_odds_difference = ((fpr_u - fpr_p) + (tpr_u - tpr_p)) / 2\n",
        "\n",
        "    # Calculate Equal Opportunity\n",
        "    equal_opportunity = tpr_u - tpr_p\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    acc = (tp_u + tp_p + tn_u + tn_p) / (tp_u + tp_p + tn_u + tn_p + fp_u + fp_p + fn_p + fn_u)\n",
        "\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "\n",
        "    return disparate_impact,demo_parity,average_odds_difference,equal_opportunity,ACC"
      ],
      "metadata": {
        "id": "LQml4VNZcUp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "from sklearn import preprocessing\n",
        "dataset_orig = pd.read_csv('adult.data.csv')\n",
        "\n",
        "## Drop NULL values\n",
        "dataset_orig = dataset_orig.dropna()\n",
        "\n",
        "## Drop categorical features\n",
        "dataset_orig = dataset_orig.drop(['workclass','fnlwgt','education','marital-status','occupation','relationship','native-country'],axis=1)\n",
        "\n",
        "## Change symbolics to numerics\n",
        "dataset_orig['sex'] = np.where(dataset_orig['sex'] == ' Male', 1, 0)\n",
        "dataset_orig['race'] = np.where(dataset_orig['race'] != ' White', 0, 1)\n",
        "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == ' <=50K', 0, 1)\n",
        "\n",
        "\n",
        "## Discretize age\n",
        "dataset_orig['age'] = np.where(dataset_orig['age'] >= 70, 70, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where((dataset_orig['age'] >= 60 ) & (dataset_orig['age'] < 70), 60, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where((dataset_orig['age'] >= 50 ) & (dataset_orig['age'] < 60), 50, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where((dataset_orig['age'] >= 40 ) & (dataset_orig['age'] < 50), 40, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where((dataset_orig['age'] >= 30 ) & (dataset_orig['age'] < 40), 30, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where((dataset_orig['age'] >= 20 ) & (dataset_orig['age'] < 30), 20, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where((dataset_orig['age'] >= 10 ) & (dataset_orig['age'] < 10), 10, dataset_orig['age'])\n",
        "dataset_orig['age'] = np.where(dataset_orig['age'] < 10, 0, dataset_orig['age'])"
      ],
      "metadata": {
        "id": "wouc3HmOdyNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predicted_Variable=\"Probability\"\n",
        "Protected_Attribute=\"sex\"#\"race\""
      ],
      "metadata": {
        "id": "IbQ-fIKLdhCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = dataset_orig.drop(Predicted_Variable,axis=1)\n",
        "y = dataset_orig[Predicted_Variable]"
      ],
      "metadata": {
        "id": "nKQmiAy9b_qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "}"
      ],
      "metadata": {
        "id": "-lcqaexMd1Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_metrics = []\n"
      ],
      "metadata": {
        "id": "1wj9U2IkVKIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Reweighting(df_train):\n",
        "    N_train = len(df_train)\n",
        "\n",
        "    df_PP = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_PP = len(df_PP)\n",
        "\n",
        "    df_UP = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_UP = len(df_UP)\n",
        "\n",
        "    df_PN = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_PN = len(df_PN)\n",
        "\n",
        "    df_UN = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_UN = len(df_UN)\n",
        "\n",
        "    df_pri= df_train[df_train[Protected_Attribute]==1]\n",
        "    N_Priviliged = len(df_pri)\n",
        "\n",
        "    df_unpri=df_train[df_train[Protected_Attribute]==0]\n",
        "    N_Un_priviliged = len(df_unpri)\n",
        "\n",
        "    df_pos=df_train[df_train[Predicted_Variable]==1]\n",
        "    N_Positive = len(df_pos)\n",
        "\n",
        "    df_neg=df_train[df_train[Predicted_Variable]==0]\n",
        "    N_Negative = len(df_neg)\n",
        "\n",
        "    W_Positive_Priviliged = (N_Priviliged * N_Positive) / (N_train * N_PP)\n",
        "    W_Positive_Un_priviliged = (N_Un_priviliged * N_Positive) / (N_train * N_UP)\n",
        "    W_Negative_Priviliged = (N_Priviliged * N_Negative) / (N_train * N_PN)\n",
        "    W_Negative_Un_priviliged = (N_Un_priviliged * N_Negative) / (N_train * N_UN)\n",
        "\n",
        "    df_train.loc[(df_train[Predicted_Variable] == 1) & (df_train[Protected_Attribute] == 1), 'weights'] = W_Positive_Priviliged\n",
        "    df_train.loc[(df_train[Predicted_Variable] == 1) & (df_train[Protected_Attribute] == 0), 'weights'] = W_Positive_Un_priviliged\n",
        "    df_train.loc[(df_train[Predicted_Variable] == 0) & (df_train[Protected_Attribute] == 1), 'weights'] = W_Negative_Priviliged\n",
        "    df_train.loc[(df_train[Predicted_Variable] == 0) & (df_train[Protected_Attribute] == 0), 'weights'] = W_Negative_Un_priviliged\n",
        "\n",
        "    X_train = df_train.drop([\"weights\", Predicted_Variable], axis=1)\n",
        "    y_train = df_train[Predicted_Variable]\n",
        "    we2 = df_train[\"weights\"].to_numpy()\n",
        "\n",
        "    return X_train, y_train, we2"
      ],
      "metadata": {
        "id": "Imkiacy6bwqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Uniform_sampling(df_train):\n",
        "\n",
        "    N_train = len(df_train)\n",
        "\n",
        "    df_PP = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_PP = len(df_PP)\n",
        "\n",
        "    df_UP = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_UP = len(df_UP)\n",
        "\n",
        "    df_PN = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_PN = len(df_PN)\n",
        "\n",
        "    df_UN = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_UN = len(df_UN)\n",
        "\n",
        "    df_pri= df_train[df_train[Protected_Attribute]==1]\n",
        "    N_Priviliged = len(df_pri)\n",
        "\n",
        "    df_unpri=df_train[df_train[Protected_Attribute]==0]\n",
        "    N_Un_priviliged = len(df_unpri)\n",
        "\n",
        "    df_pos=df_train[df_train[Predicted_Variable]==1]\n",
        "    N_Positive = len(df_pos)\n",
        "\n",
        "    df_neg=df_train[df_train[Predicted_Variable]==0]\n",
        "    N_Negative = len(df_neg)\n",
        "\n",
        "    W_Positive_Priviliged = (N_Priviliged * N_Positive) / (N_train * N_PP)\n",
        "    W_Positive_Un_priviliged = (N_Un_priviliged * N_Positive) / (N_train * N_UP)\n",
        "    W_Negative_Priviliged = (N_Priviliged * N_Negative) / (N_train * N_PN)\n",
        "    W_Negative_Un_priviliged = (N_Un_priviliged * N_Negative) / (N_train * N_UN)\n",
        "\n",
        "    S_PP = round(W_Positive_Priviliged * N_PP)\n",
        "    S_UP = round(W_Positive_Un_priviliged * N_UP)\n",
        "    S_PN = round(W_Negative_Priviliged * N_PN)\n",
        "    S_UN = round(W_Negative_Un_priviliged * N_UN)\n",
        "\n",
        "    sample_df_PP = df_PP.sample(S_PP, replace=False)\n",
        "    sample_df_UP = df_UP.sample(S_UP, replace=True)\n",
        "    sample_df_PN = df_PN.sample(S_PN, replace=True)\n",
        "    sample_df_UN = df_UN.sample(S_UN, replace=False)\n",
        "\n",
        "    list_concat = [sample_df_PP, sample_df_UP, sample_df_PN, sample_df_UN]\n",
        "    sample_df = pd.concat(list_concat)\n",
        "    X_train_s = sample_df.drop([Predicted_Variable], axis=1)\n",
        "    y_train_s = sample_df[Predicted_Variable]\n",
        "\n",
        "    return X_train_s, y_train_s"
      ],
      "metadata": {
        "id": "K9Az9mbsVP1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######to pick samples close to decision boundry\n",
        "\n",
        "def UP_sampling(df, num_samples):\n",
        "    num_samples = abs(num_samples)  # Convert num_samples to its absolute value\n",
        "\n",
        "    total_rows = len(df)\n",
        "    sampled_df = pd.DataFrame()  # Initialize an empty DataFrame to store sampled data\n",
        "\n",
        "    while len(sampled_df) < num_samples:\n",
        "        remaining_samples = num_samples - len(sampled_df)\n",
        "\n",
        "        # If remaining samples needed are greater than the total rows, duplicate the entire DataFrame\n",
        "        if remaining_samples >= total_rows:\n",
        "            sampled_df = pd.concat([sampled_df, df], ignore_index=True)\n",
        "        else:\n",
        "            # Otherwise, concatenate a subset of rows from the top of the DataFrame\n",
        "            sampled_df = pd.concat([sampled_df, df.head(remaining_samples)], ignore_index=True)\n",
        "\n",
        "    return sampled_df"
      ],
      "metadata": {
        "id": "W4pJqhfzVP4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preferential_samples(X_train,y_train):\n",
        "\n",
        "    df_train = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "    #scaled_X_train_ranker = scaler.fit_transform(X_train)\n",
        "    ranker_model = LogisticRegression()\n",
        "    ranker_model.fit(X_train, y_train)\n",
        "    positive_probs_R = ranker_model.predict_proba(X_train)[:, 1]\n",
        "    df_train[\"p_probablity\"]=positive_probs_R\n",
        "\n",
        "    N_train = len(df_train)\n",
        "\n",
        "    df_PP = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_PP = len(df_PP)\n",
        "\n",
        "    df_UP = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_UP = len(df_UP)\n",
        "\n",
        "    df_PN = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_PN = len(df_PN)\n",
        "\n",
        "    df_UN = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_UN = len(df_UN)\n",
        "\n",
        "    df_pri= df_train[df_train[Protected_Attribute]==1]\n",
        "    N_Priviliged = len(df_pri)\n",
        "\n",
        "    df_unpri=df_train[df_train[Protected_Attribute]==0]\n",
        "    N_Un_priviliged = len(df_unpri)\n",
        "\n",
        "    df_pos=df_train[df_train[Predicted_Variable]==1]\n",
        "    N_Positive = len(df_pos)\n",
        "\n",
        "    df_neg=df_train[df_train[Predicted_Variable]==0]\n",
        "    N_Negative = len(df_neg)\n",
        "\n",
        "    W_Positive_Priviliged = (N_Priviliged * N_Positive) / (N_train * N_PP)\n",
        "    W_Positive_Un_priviliged = (N_Un_priviliged * N_Positive) / (N_train * N_UP)\n",
        "    W_Negative_Priviliged = (N_Priviliged * N_Negative) / (N_train * N_PN)\n",
        "    W_Negative_Un_priviliged = (N_Un_priviliged * N_Negative) / (N_train * N_UN)\n",
        "\n",
        "    S_PP = round(W_Positive_Priviliged * N_PP)\n",
        "    S_UP = round(W_Positive_Un_priviliged * N_UP)\n",
        "    S_PN = round(W_Negative_Priviliged * N_PN)\n",
        "    S_UN = round(W_Negative_Un_priviliged * N_UN)\n",
        "\n",
        "    PP=df_PP.sort_values(by=\"p_probablity\", axis=0, ascending=True, inplace=False, key=None)\n",
        "    UP=df_UP.sort_values(by=\"p_probablity\", axis=0, ascending=True, inplace=False, key=None)\n",
        "    UN=df_UN.sort_values(by=['p_probablity'], axis=0, ascending=False, inplace=False, key=None)\n",
        "    PN=df_PN.sort_values(by=['p_probablity'], axis=0, ascending=False, inplace=False, key=None)\n",
        "\n",
        "\n",
        "    sample_UP = UP_sampling(UP, S_UP)\n",
        "\n",
        "    sample_PN = UP_sampling(PN, S_PN)\n",
        "\n",
        "    sample_UN = UN.tail(S_UN)\n",
        "    sample_PP = PP.tail(S_PP)\n",
        "\n",
        "\n",
        "    list_concat = [sample_UP,sample_UN,sample_PP,sample_PN]\n",
        "    new_df = pd.concat(list_concat)\n",
        "\n",
        "    X_train_ps = new_df.drop([Predicted_Variable,\"p_probablity\"], axis=1)\n",
        "    y_train_ps = new_df[Predicted_Variable]\n",
        "\n",
        "    return X_train_ps, y_train_ps"
      ],
      "metadata": {
        "id": "CeyI3sHpVP7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Fair_Smote(df_train):\n",
        "\n",
        "    N_train = len(df_train)\n",
        "\n",
        "    df_PP = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_PP = len(df_PP)\n",
        "\n",
        "    df_UP = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 1)]\n",
        "    N_UP = len(df_UP)\n",
        "\n",
        "    df_PN = df_train[(df_train[Protected_Attribute] == 1) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_PN = len(df_PN)\n",
        "\n",
        "    df_UN = df_train[(df_train[Protected_Attribute] == 0) & (df_train[Predicted_Variable] == 0)]\n",
        "    N_UN = len(df_UN)\n",
        "\n",
        "\n",
        "    # Calculate maximum count\n",
        "    maximum = max(N_PP,N_UP,N_PN,N_UN)\n",
        "\n",
        "    # Calculate number of samples to be generated for each class and protected attribute combination\n",
        "    df_PP_to_be_increased = maximum - N_PP\n",
        "    df_UP_to_be_increased = maximum - N_UP\n",
        "    df_PN_to_be_increased = maximum - N_PN\n",
        "    df_UN_to_be_increased = maximum - N_UN\n",
        "\n",
        "    # Generate synthetic samples\n",
        "    df_new_PP = generate_samples(df_PP_to_be_increased, df_PP, 'Adult')\n",
        "    df_new_UP = generate_samples(df_UP_to_be_increased, df_UP, 'Adult')\n",
        "    df_new_PN = generate_samples(df_PN_to_be_increased, df_PN, 'Adult')\n",
        "    df_new_UN = generate_samples(df_UN_to_be_increased, df_UN, 'Adult')\n",
        "\n",
        "    # Combine the resampled data\n",
        "    df_train_resampled = pd.concat([df_new_PP, df_new_UP, df_new_PN, df_new_UN])\n",
        "    X_train_resampled = df_train_resampled.drop(Predicted_Variable, axis=1)\n",
        "    y_train_resampled = df_train_resampled[Predicted_Variable]\n",
        "\n",
        "    return X_train_resampled, y_train_resampled"
      ],
      "metadata": {
        "id": "kP5YCt6UVch6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "#its results is different with when run ps alone\n",
        "###########################\n",
        "\n",
        "n_splits = 10\n",
        "\n",
        "# Perform cross-validation for each classifier\n",
        "for clf_name, clf in classifiers.items():\n",
        "    accuracy_original_list = []\n",
        "    balanced_original_list = []\n",
        "    disparate_impact_original_list = []\n",
        "    demo_parity_original_list = []\n",
        "    average_odds_difference_original_list = []\n",
        "    equal_opportunity_original_list = []\n",
        "\n",
        "    accuracy_reweight_list = []\n",
        "    balanced_reweight_list = []\n",
        "    disparate_impact_reweight_list = []\n",
        "    demo_parity_reweight_list = []\n",
        "    average_odds_difference_reweight_list = []\n",
        "    equal_opportunity_reweight_list = []\n",
        "\n",
        "    accuracy_sample_list = []\n",
        "    balanced_sample_list = []\n",
        "    disparate_impact_sample_list = []\n",
        "    demo_parity_sample_list = []\n",
        "    average_odds_difference_sample_list = []\n",
        "    equal_opportunity_sample_list = []\n",
        "\n",
        "    accuracy_ps_list = []\n",
        "    balanced_ps_list = []\n",
        "    disparate_impact_ps_list = []\n",
        "    demo_parity_ps_list = []\n",
        "    average_odds_difference_ps_list = []\n",
        "    equal_opportunity_ps_list = []\n",
        "\n",
        "\n",
        "    accuracy_fs_list = []\n",
        "    balanced_fs_list = []\n",
        "    disparate_impact_fs_list = []\n",
        "    demo_parity_fs_list = []\n",
        "    average_odds_difference_fs_list = []\n",
        "    equal_opportunity_fs_list = []\n",
        "\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=101)\n",
        "\n",
        "    # Perform cross-validation\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        ##########################################baseline\n",
        "        X_train_original = X_train\n",
        "        X_test_original = X_test\n",
        "        # Fit classifier with original data\n",
        "\n",
        "        # Scale the data\n",
        "        X_train_scaled_original = scaler.fit_transform(X_train_original)\n",
        "        X_test_scaled_original = scaler.transform(X_test_original)\n",
        "\n",
        "        clf.fit(X_train_scaled_original, y_train)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = clf.predict(X_test_scaled_original)\n",
        "\n",
        "        # Compute metrics for original data\n",
        "        disparate_impact, demo_parity, average_odds_difference, equal_opportunity, acc = compute_metrics(y_test, y_pred, X_test[Protected_Attribute])\n",
        "\n",
        "        # Append metrics to respective lists\n",
        "        disparate_impact_original_list.append(disparate_impact)\n",
        "        demo_parity_original_list.append(demo_parity)\n",
        "        average_odds_difference_original_list.append(average_odds_difference)\n",
        "        equal_opportunity_original_list.append(equal_opportunity)\n",
        "\n",
        "        # Compute accuracy scores\n",
        "        accur_orig = accuracy_score(y_test, y_pred)\n",
        "        balanced_orig = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Append computed accuracy scores\n",
        "        accuracy_original_list.append(accur_orig)\n",
        "        balanced_original_list.append(balanced_orig)\n",
        "\n",
        "\n",
        "        #################################################### Applying reweighting\n",
        "        X_train_reweight, y_train_reweight, we2 = Reweighting(pd.concat([X_train, y_train], axis=1))\n",
        "\n",
        "        # Scale the data\n",
        "        X_train_scaled_reweight = scaler.fit_transform(X_train_reweight)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Fit classifier with reweighted data\n",
        "        clf.fit(X_train_scaled_reweight, y_train_reweight, sample_weight=we2)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "        # Compute metrics for reweighted data\n",
        "        disparate_impact, demo_parity, average_odds_difference, equal_opportunity, acc = compute_metrics(y_test, y_pred, X_test[Protected_Attribute])\n",
        "\n",
        "        # Append metrics to respective lists\n",
        "        disparate_impact_reweight_list.append(disparate_impact)\n",
        "        demo_parity_reweight_list.append(demo_parity)\n",
        "        average_odds_difference_reweight_list.append(average_odds_difference)\n",
        "        equal_opportunity_reweight_list.append(equal_opportunity)\n",
        "\n",
        "        # Compute accuracy scores\n",
        "        accur_re = accuracy_score(y_test, y_pred)\n",
        "        balanced_re = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Append computed accuracy scores\n",
        "        accuracy_reweight_list.append(accur_re)\n",
        "        balanced_reweight_list.append(balanced_re)\n",
        "\n",
        "        ####################################### Applying US_samples\n",
        "        X_train_sample, y_train_sample = Uniform_sampling(pd.concat([X_train, y_train], axis=1))\n",
        "\n",
        "        # Scale the data\n",
        "        X_train_scaled_sample = scaler.fit_transform(X_train_sample)\n",
        "\n",
        "        # Fit classifier with sampled data\n",
        "        clf.fit(X_train_scaled_sample, y_train_sample)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "        # Compute metrics for sampled data\n",
        "        disparate_impact, demo_parity, average_odds_difference, equal_opportunity, acc = compute_metrics(y_test, y_pred, X_test[Protected_Attribute])\n",
        "\n",
        "        # Append metrics to respective lists\n",
        "        disparate_impact_sample_list.append(disparate_impact)\n",
        "        demo_parity_sample_list.append(demo_parity)\n",
        "        average_odds_difference_sample_list.append(average_odds_difference)\n",
        "        equal_opportunity_sample_list.append(equal_opportunity)\n",
        "\n",
        "        # Compute accuracy scores\n",
        "        accur_us = accuracy_score(y_test, y_pred)\n",
        "        balanced_us = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Append computed accuracy scores\n",
        "        accuracy_sample_list.append(accur_us)\n",
        "        balanced_sample_list.append(balanced_us)\n",
        "\n",
        "        ####################################### Applying preferential sampling\n",
        "        X_train_ps, y_train_ps = preferential_samples(X_train, y_train)\n",
        "\n",
        "        # Scale the data\n",
        "        X_train_scaled_ps = scaler.fit_transform(X_train_ps)\n",
        "\n",
        "        # Fit classifier with preferentially sampled data\n",
        "        clf.fit(X_train_scaled_ps, y_train_ps)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "        # Compute metrics for preferentially sampled data\n",
        "        disparate_impact, demo_parity, average_odds_difference, equal_opportunity, acc = compute_metrics(y_test, y_pred, X_test[Protected_Attribute])\n",
        "\n",
        "        # Append metrics to respective lists\n",
        "        disparate_impact_ps_list.append(disparate_impact)\n",
        "        demo_parity_ps_list.append(demo_parity)\n",
        "        average_odds_difference_ps_list.append(average_odds_difference)\n",
        "        equal_opportunity_ps_list.append(equal_opportunity)\n",
        "\n",
        "        # Compute accuracy scores\n",
        "        accur_ps = accuracy_score(y_test, y_pred)\n",
        "        balanced_ps = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Append computed accuracy scores\n",
        "        accuracy_ps_list.append(accur_ps)\n",
        "        balanced_ps_list.append(balanced_ps)\n",
        "\n",
        "\n",
        "        ####################################### Applying Fair_smote\n",
        "        X_train_Fair_SMOTE, y_train_Fair_SMOTE = Fair_Smote(pd.concat([X_train, y_train], axis=1))\n",
        "\n",
        "        # Scale the data\n",
        "        X_train_scaled_FS = scaler.fit_transform(X_train_Fair_SMOTE)\n",
        "\n",
        "        # Fit classifier with sampled data\n",
        "        clf.fit( X_train_scaled_FS, y_train_Fair_SMOTE)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "        # Compute metrics for sampled data\n",
        "        disparate_impact, demo_parity, average_odds_difference, equal_opportunity, acc = compute_metrics(y_test, y_pred, X_test[Protected_Attribute])\n",
        "\n",
        "        # Append metrics to respective lists\n",
        "        disparate_impact_fs_list.append(disparate_impact)\n",
        "        demo_parity_fs_list.append(demo_parity)\n",
        "        average_odds_difference_fs_list.append(average_odds_difference)\n",
        "        equal_opportunity_fs_list.append(equal_opportunity)\n",
        "\n",
        "        # Compute accuracy scores\n",
        "        accur_fs = accuracy_score(y_test, y_pred)\n",
        "        balanced_fs = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Append computed accuracy scores\n",
        "        accuracy_fs_list.append(accur_fs)\n",
        "        balanced_fs_list.append(balanced_fs)\n",
        "\n",
        "    ######################## Compute average metrics across folds for original data\n",
        "    accuracy_original = np.median(accuracy_original_list)\n",
        "    balanced_accuracy_original = np.median(balanced_original_list)\n",
        "    disparate_impact_original = np.median(disparate_impact_original_list)\n",
        "    demo_parity_original = np.median(demo_parity_original_list)\n",
        "    average_odds_difference_original = np.median(average_odds_difference_original_list)\n",
        "    equal_opportunity_original = np.median(equal_opportunity_original_list)\n",
        "\n",
        "    ######################### Compute average metrics across folds for reweighted data\n",
        "    accuracy_reweight = np.median(accuracy_reweight_list)\n",
        "    balanced_accuracy_reweight = np.median(balanced_reweight_list)\n",
        "    disparate_impact_reweight = np.median(disparate_impact_reweight_list)\n",
        "    demo_parity_reweight = np.median(demo_parity_reweight_list)\n",
        "    average_odds_difference_reweight = np.median(average_odds_difference_reweight_list)\n",
        "    equal_opportunity_reweight = np.median(equal_opportunity_reweight_list)\n",
        "\n",
        "    ########################## Compute average metrics across folds for sampled data\n",
        "    accuracy_sample = np.median(accuracy_sample_list)\n",
        "    balanced_accuracy_sample = np.median(balanced_sample_list)\n",
        "    disparate_impact_sample = np.median(disparate_impact_sample_list)\n",
        "    demo_parity_sample = np.median(demo_parity_sample_list)\n",
        "    average_odds_difference_sample = np.median(average_odds_difference_sample_list)\n",
        "    equal_opportunity_sample = np.median(equal_opportunity_sample_list)\n",
        "\n",
        "    ############################ Compute average metrics across folds for preferentially sampled data\n",
        "    accuracy_ps = np.median(accuracy_ps_list)\n",
        "    balanced_accuracy_ps = np.median(balanced_ps_list)\n",
        "    disparate_impact_ps = np.median(disparate_impact_ps_list)\n",
        "    demo_parity_ps = np.median(demo_parity_ps_list)\n",
        "    average_odds_difference_ps = np.median(average_odds_difference_ps_list)\n",
        "    equal_opportunity_ps = np.median(equal_opportunity_ps_list)\n",
        "\n",
        "        ############################ Compute average metrics across folds for fair-smote sampled data\n",
        "    accuracy_fs = np.median(accuracy_fs_list)\n",
        "    balanced_accuracy_fs = np.median(balanced_fs_list)\n",
        "    disparate_impact_fs = np.median(disparate_impact_fs_list)\n",
        "    demo_parity_fs = np.median(demo_parity_fs_list)\n",
        "    average_odds_difference_fs = np.median(average_odds_difference_fs_list)\n",
        "    equal_opportunity_fs = np.median(equal_opportunity_fs_list)\n",
        "\n",
        "    # Append metrics to the classifier_metrics list\n",
        "    classifier_metrics.append([clf_name + \" (Baseline)\", accuracy_original, balanced_accuracy_original, disparate_impact_original, demo_parity_original, average_odds_difference_original, equal_opportunity_original])\n",
        "    classifier_metrics.append([clf_name + \" (Reweighting)\", accuracy_reweight, balanced_accuracy_reweight, disparate_impact_reweight, demo_parity_reweight, average_odds_difference_reweight, equal_opportunity_reweight])\n",
        "    classifier_metrics.append([clf_name + \" (Uniform Sampling)\", accuracy_sample, balanced_accuracy_sample, disparate_impact_sample, demo_parity_sample, average_odds_difference_sample, equal_opportunity_sample])\n",
        "    classifier_metrics.append([clf_name + \" (Preferential Sampling)\", accuracy_ps, balanced_accuracy_ps, disparate_impact_ps, demo_parity_ps, average_odds_difference_ps, equal_opportunity_ps])\n",
        "    classifier_metrics.append([clf_name + \" (Fair_SMOTE)\", accuracy_fs, balanced_accuracy_fs, disparate_impact_fs, demo_parity_fs, average_odds_difference_fs, equal_opportunity_fs])\n",
        "\n",
        "# Create a DataFrame\n",
        "metrics_df = pd.DataFrame(classifier_metrics, columns=['Classifier', 'Accuracy', 'Balanced Accuracy', 'Disparate Impact', 'Demographic Parity', 'Average Odds Difference', 'Equal Opportunity'])\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "metrics_df.to_excel('classifier_base_re_us_ps_fs_metrics.xlsx', index=False)\n",
        "\n",
        "# Create a link for downloading the Excel file\n",
        "FileLink(r'classifier_base_re_us_ps_fs_metrics.xlsx')"
      ],
      "metadata": {
        "id": "lt_xOTwzVP-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnalAk0fVQCY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}